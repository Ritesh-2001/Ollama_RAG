{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import arxiv\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "#from langchain_community import embeddings\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_stdlib_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Ollama RAG pipeline which automatically retrieves top arxiv papers related to 'LLMs in Telecom sector' and model (llama2 or mistral) uses these papers as context to produce more relavant and accurate responses\n",
    "### - Ragas Library is to asses the RAG pipeline based on metrics like faithfulness, context_precision, context_recall and answer_relevancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Ragas library doesn't work with llama2 but works with mistral since ragas was initially designed for openaai models but with a workaround I have used mistral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First download ollama form ollama.com/download and then start it by running the ollama file\n",
    "- Before executing notebook, do following in cmd\n",
    "- enter virtual environment and then\n",
    "- ollama pull mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/explodinggradients/ragas.git\n",
    "# !pip install -U langchain langchain-community langchain-core BeautifulSoup4 tiktoken chromadb arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Paper id 2308.06013v2 with title 'Large Language Models for Telecom: Forthcoming Impact on the Industry' is downloaded.\n",
      "-> Paper id 2306.07933v1 with title 'Understanding Telecom Language Through Large Language Models' is downloaded.\n",
      "-> Paper id 2310.15051v1 with title 'TeleQnA: A Benchmark Dataset to Assess Large Language Models Telecommunications Knowledge' is downloaded.\n",
      "-> Paper id 2310.11770v1 with title 'Telecom AI Native Systems in the Age of Generative AI -- An Engineering Perspective' is downloaded.\n",
      "-> Paper id 2305.13102v1 with title 'Observations on LLMs for Telecom Domain: Capabilities and Limitations' is downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Create directory if not exists\n",
    "dirpath = \"arxiv_papers_ragas\"\n",
    "if not os.path.exists(dirpath):\n",
    "    os.makedirs(dirpath)\n",
    "\n",
    "# Search arXiv for papers related to \"LLM\" (combination of keyword matching and most relavant)\n",
    "client = arxiv.Client()\n",
    "search = arxiv.Search(\n",
    "    query=\"LLM AND telecom\", # AND is Boolean operator here\n",
    "    max_results=5,\n",
    "    sort_order=arxiv.SortOrder.Descending\n",
    ")\n",
    "\n",
    "# Download and save the papers\n",
    "for result in client.results(search):\n",
    "    while True:\n",
    "        try:\n",
    "            result.download_pdf(dirpath=dirpath)\n",
    "            print(f\"-> Paper id {result.get_short_id()} with title '{result.title}' is downloaded.\")\n",
    "            break\n",
    "        except (FileNotFoundError, ConnectionResetError) as e:\n",
    "            print(\"Error occurred:\", e)\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pages loaded: 38\n",
      "Total characters in the concatenated text: 163000\n",
      "text splitted into chunks\n"
     ]
    }
   ],
   "source": [
    "# Load papers from the directory\n",
    "papers = []\n",
    "loader = DirectoryLoader(dirpath, glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
    "try:\n",
    "    papers = loader.load()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")\n",
    "print(\"Total number of pages loaded:\", len(papers))\n",
    "\n",
    "# Concatenate all pages' content into a single string\n",
    "full_text = ''\n",
    "for paper in papers:\n",
    "    full_text += paper.page_content\n",
    "\n",
    "# Remove empty lines and join lines into a single string\n",
    "full_text = \" \".join(line for line in full_text.splitlines() if line)\n",
    "print(\"Total characters in the concatenated text:\", len(full_text))\n",
    "\n",
    "# Split the text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "paper_chunks = text_splitter.create_documents([full_text])\n",
    "\n",
    "print(\"text splitted into chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert documents to Embeddings and store them\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=paper_chunks,\n",
    "    collection_name=\"arxiv_papers\",\n",
    "    embedding=GPT4AllEmbeddings(),\n",
    "    #embedding=embeddings.ollama.OllamaEmbeddings(model='nomic-embed-text'),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Define prompt template\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Initialize Ollama LLM\n",
    "ollama_llm = \"mistral\" #can use llama2 as well\n",
    "model = ChatOllama(model=ollama_llm)\n",
    "\n",
    "# Define the processing chain\n",
    "chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Add typing for input\n",
    "class Question(BaseModel):\n",
    "    __root__: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS library - RAG Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Model incapable of producing valid JSON outputs leads to JSON warning and hence NaN output (for answer recall and faithfulness)\n",
    "- context recall runs properly but context_precision gives list doesn't have get function error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness\n",
    ")\n",
    "\n",
    "# Sample questions and ground truths for LLM in telecom sector\n",
    "questions = [\n",
    "    \"In a sentence what are the applications of LLM in the telecom sector?\"\n",
    "]\n",
    "\n",
    "ground_truth = [\n",
    "    \"Large Language Models (LLMs) are revolutionizing the telecom industry by enhancing network performance, streamlining difficult tasks ,Task automation, security, and customer experiences.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' The applications of Large Language Models (LLMs) in the telecom sector include use cases that leverage available data for industry-specific purposes, with potential benefits from addressing open research directions such as improving practical implementation knowledge and narrowing the performance gap between context-aware LLMs and traditional models.']\n",
      "[['blocks to unlock their potential. V. C ONCLUSIONS In this article, we have delved into the inner workings of LLMs, shedding light on their current capabilities and limitations. Additionally, we explored various use cases of LLMs that can be promptly leveraged within the industry using the available data at vendors’ disposal. Furthermore, we discussed the specific open research directions tailored to the peculiarities of the telecom domain, which must be addressed to fully harness the potential', 'blocks to unlock their potential. V. C ONCLUSIONS In this article, we have delved into the inner workings of LLMs, shedding light on their current capabilities and limitations. Additionally, we explored various use cases of LLMs that can be promptly leveraged within the industry using the available data at vendors’ disposal. Furthermore, we discussed the specific open research directions tailored to the peculiarities of the telecom domain, which must be addressed to fully harness the potential', 'directions presents itself. These avenues of investigation are crucial to unlock the full potential of LLMs in the telecom industry and harness their capabilities to the utmost extent. A. Telecom Foundation Model While the most advanced foundation models exhibit a reasonable grasp of the telecommunications theory, they fall short on practical implementation knowledge [12]. Besides, our findings, illustrated in Fig. 4, have demonstrated the performance gap between a context-aware LLM and a', 'directions presents itself. These avenues of investigation are crucial to unlock the full potential of LLMs in the telecom industry and harness their capabilities to the utmost extent. A. Telecom Foundation Model While the most advanced foundation models exhibit a reasonable grasp of the telecommunications theory, they fall short on practical implementation knowledge [12]. Besides, our findings, illustrated in Fig. 4, have demonstrated the performance gap between a context-aware LLM and a']]\n"
     ]
    }
   ],
   "source": [
    "# Inference for the provided questions\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(chain.invoke(query))\n",
    "    contexts.append([docs.page_content for docs in retriever.get_relevant_documents(query)])\n",
    "\n",
    "print(answers)\n",
    "print(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
      "    num_rows: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Ragas wants ['question', 'answer', 'contexts', 'ground_truths'] as\n",
    "'''\n",
    "{\n",
    "    \"question\": [], <-- question \n",
    "    \"answer\": [], <-- answer from generated result\n",
    "    \"contexts\": [[]], <-- context (list of lists)\n",
    "    \"ground_truth\": [] <-- actual answer\n",
    "}\n",
    "'''\n",
    "\n",
    "# Organize the data into a dictionary\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truth\": ground_truth\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a dataset\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: In a sentence what are the applications of LLM in the telecom sector?\n",
      "Answer:  The applications of Large Language Models (LLMs) in the telecom sector include use cases that leverage available data for industry-specific purposes, with potential benefits from addressing open research directions such as improving practical implementation knowledge and narrowing the performance gap between context-aware LLMs and traditional models.\n",
      "Contexts: ['LLMs are being used to improve network performance in the telecom sector and Telecom companies are exploring how LLMs can automate tasks like network monitoring.']\n",
      "Ground Truth: Large Language Models (LLMs) are revolutionizing the telecom industry by enhancing network performance, streamlining difficult tasks ,Task automation, security, and customer experiences.\n"
     ]
    }
   ],
   "source": [
    "first_row = dataset[0]  # Access the first row as a dictionary\n",
    "question = first_row['question']\n",
    "answer = first_row['answer']\n",
    "contexts = first_row['contexts']\n",
    "ground_truth = first_row['ground_truth']\n",
    "\n",
    "\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)\n",
    "print(\"Contexts:\", contexts)\n",
    "print(\"Ground Truth:\", ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "template for running models without openai_api_key\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "langchain_llm = BaseLanguageModel(model=\"my_model\") # any langchain LLM instance\n",
    "langchain_embeddings = Embeddings(model=\"my_model\") # any langchain Embeddings instance\n",
    "\n",
    "results = evaluate(metrics=[], llm=langchain_llm, embeddings=embeddings)\n",
    "'''\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings_ollama = OllamaEmbeddings(model=\"mistral\") \n",
    "\n",
    "from ragas import evaluate\n",
    "result = evaluate(\n",
    "    dataset=dataset,\n",
    "    metrics=[\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        context_precision,\n",
    "        answer_relevancy\n",
    "    ],\n",
    "    llm=model,\n",
    "    embeddings=embeddings_ollama,\n",
    "    raise_exceptions=False\n",
    "    \n",
    ")\n",
    "\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In a sentence what are the applications of LLM in the telecom sector?</td>\n",
       "      <td>The applications of Large Language Models (LLMs) in the telecom sector include use cases that leverage available data for industry-specific purposes, with potential benefits from addressing open research directions such as improving practical implementation knowledge and narrowing the performance gap between context-aware LLMs and traditional models.</td>\n",
       "      <td>[LLMs are being used to improve network performance in the telecom sector and Telecom companies are exploring how LLMs can automate tasks like network monitoring.]</td>\n",
       "      <td>Large Language Models (LLMs) are revolutionizing the telecom industry by enhancing network performance, streamlining difficult tasks ,Task automation, security, and customer experiences.</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                question  \\\n",
       "0  In a sentence what are the applications of LLM in the telecom sector?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                              answer  \\\n",
       "0   The applications of Large Language Models (LLMs) in the telecom sector include use cases that leverage available data for industry-specific purposes, with potential benefits from addressing open research directions such as improving practical implementation knowledge and narrowing the performance gap between context-aware LLMs and traditional models.   \n",
       "\n",
       "                                                                                                                                                              contexts  \\\n",
       "0  [LLMs are being used to improve network performance in the telecom sector and Telecom companies are exploring how LLMs can automate tasks like network monitoring.]   \n",
       "\n",
       "                                                                                                                                                                                 ground_truth  \\\n",
       "0  Large Language Models (LLMs) are revolutionizing the telecom industry by enhancing network performance, streamlining difficult tasks ,Task automation, security, and customer experiences.   \n",
       "\n",
       "   context_recall  faithfulness  context_precision  answer_relevancy  \n",
       "0        0.666667          0.75                1.0          0.670276  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df = result.to_pandas()\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
